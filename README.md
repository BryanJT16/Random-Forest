# Predicci√≥n de Diabetes ‚Äì √Årboles, Random Forest y Boosting

üìò **Descripci√≥n del Proyecto**
Este proyecto es la continuaci√≥n del modelo inicial basado en √Årboles de Decisi√≥n para la predicci√≥n de diabetes. En esta segunda fase se ampl√≠a el enfoque incorporando modelos de ensamble m√°s avanzados como **Random Forest** y distintos m√©todos de **Boosting**, con el objetivo de mejorar la capacidad predictiva, la estabilidad del modelo y su generalizaci√≥n sobre datos no vistos.

üß© **Contexto**
Aunque los √Årboles de Decisi√≥n ofrecen una gran interpretabilidad, suelen presentar problemas de sobreajuste y alta varianza cuando se utilizan de forma individual. Para abordar estas limitaciones, se exploran t√©cnicas de ensamble que combinan m√∫ltiples √°rboles de decisi√≥n. Estas t√©cnicas permiten capturar patrones m√°s complejos y reducir el error del modelo, algo especialmente relevante en un contexto cl√≠nico donde la fiabilidad de las predicciones es crucial.

üéØ **Objetivos**

* Extender el modelo inicial de √Årbol de Decisi√≥n mediante t√©cnicas de ensamble.
* Implementar y comparar un **Random Forest Classifier**.
* Aplicar distintos m√©todos de **Boosting** (Gradient Boosting y XGBoost).
* Evaluar y comparar el rendimiento de los modelos.
* Seleccionar y guardar el mejor modelo final para su uso posterior.

üìä **Resumen de Caracter√≠sticas**
El modelo utiliza variables cl√≠nicas comunes para la predicci√≥n de diabetes:

* **Pregnancies**: N√∫mero de embarazos
* **Glucose**: Concentraci√≥n de glucosa en plasma
* **BloodPressure**: Presi√≥n arterial diast√≥lica
* **SkinThickness**: Grosor del pliegue cut√°neo
* **Insulin**: Insulina s√©rica
* **BMI**: √çndice de masa corporal
* **DiabetesPedigreeFunction**: Historial familiar de diabetes
* **Age**: Edad del paciente
* **Outcome**: Variable objetivo (0 = no diabetes, 1 = diabetes)

üöÄ **Metodolog√≠a**

### 1. Preprocesamiento de Datos

* Conversi√≥n de valores biol√≥gicamente imposibles (ceros) en valores nulos.
* Imputaci√≥n de valores faltantes utilizando estad√≠sticas robustas (mediana).
* Separaci√≥n de los datos en conjuntos de entrenamiento y prueba.

### 2. Modelos Implementados

#### √Årbol de Decisi√≥n

Se parte del modelo base previamente entrenado, utilizado como referencia para la comparaci√≥n.

#### Random Forest

* Construcci√≥n de un bosque de m√∫ltiples √°rboles de decisi√≥n.
* Reducci√≥n de la varianza mediante muestreo aleatorio de datos y caracter√≠sticas.
* Mejora de la estabilidad y capacidad de generalizaci√≥n.

#### Boosting

Se implementan diferentes enfoques de boosting:

##### Gradient Boosting

* Entrenamiento secuencial de √°rboles.
* Cada nuevo √°rbol corrige los errores del anterior.
* Especialmente eficaz en la reducci√≥n del sesgo.

##### XGBoost

* Implementaci√≥n optimizada de Gradient Boosting.
* Mayor eficiencia computacional.
* Mejor manejo del sobreajuste mediante regularizaci√≥n.

### 3. Evaluaci√≥n de Modelos

* Comparaci√≥n de m√©tricas de rendimiento (accuracy y otros indicadores).
* Identificaci√≥n del mejor modelo de Boosting.

### 4. Persistencia del Modelo

* Guardado del mejor modelo final entrenado para su reutilizaci√≥n futura.

üß† **Fundamentos Te√≥ricos**

#### ¬øPor qu√© usar modelos de ensamble?

Los modelos de ensamble combinan m√∫ltiples modelos d√©biles para construir un modelo fuerte. En el caso de los √°rboles:

* Reducen el sobreajuste.
* Mejoran la robustez ante ruido.
* Capturan relaciones no lineales complejas.

#### Diferencia entre Random Forest y Boosting

* **Random Forest**: √°rboles independientes entrenados en paralelo.
* **Boosting**: √°rboles dependientes entrenados de forma secuencial.

‚öôÔ∏è **Aplicaci√≥n en este Proyecto**
El uso de Random Forest y Boosting permite obtener modelos m√°s precisos que el √Årbol de Decisi√≥n individual, manteniendo un equilibrio entre interpretabilidad y rendimiento. El modelo final puede utilizarse como herramienta de apoyo para la detecci√≥n temprana de pacientes con alto riesgo de diabetes.

üß† **Tecnolog√≠as Utilizadas**

* Python
* Pandas, NumPy
* Matplotlib, Seaborn
* Scikit-learn
* XGBoost
* Jupyter Notebook

üë§ **Autor**
**Bryan Jumbo Torres**
üìç Mallorca, Espa√±a
üíª Proyecto acad√©mico / profesional de Machine Learning
